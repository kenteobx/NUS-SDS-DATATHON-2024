{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srisP5hKRwqe"
      },
      "source": [
        "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
        "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "owtumc7TRwqh",
        "outputId": "47f12077-01cd-4921-9a20-988814b1b4b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install matplotlib\n",
        "%pip install tensorflow\n",
        "%pip install sklearn\n",
        "\n",
        "# add commented pip installation lines for packages used as shown above for ease of testing\n",
        "# the line should be of the format %pip install PACKAGE_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ilvxgZRwqi"
      },
      "source": [
        "## **DO NOT CHANGE** the filepath variable\n",
        "##### Instead, create a folder named 'data' in your current working directory and\n",
        "##### have the .csv file inside that. A relative path *must* be used when loading data into pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMKIBimArr7u"
      },
      "outputs": [],
      "source": [
        "#connecting to data stored in google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APVJw8DSGkBc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "Mz4pSt68Rwqi",
        "outputId": "dc042cc2-e11f-4aa6-f8ce-7457b7d5355e"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './data/catA_train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-28ba5e9e47b1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/catA_train.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/catA_train.csv'"
          ]
        }
      ],
      "source": [
        "filepath = \"./data/catA_train.csv\"\n",
        "data = pd.read_csv(filepath)\n",
        "print(data)\n",
        "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU-upeWFgpul"
      },
      "outputs": [],
      "source": [
        "filepath = \"/content/drive/MyDrive/data\"\n",
        "data = pd.read_csv(filepath, error_bad_lines=False)\n",
        "/content/drive/MyDrive/data/catA_train.csv\n",
        "data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAAhbWEzRwqi"
      },
      "source": [
        "### **ALL** Code for machine learning and dataset analysis should be entered below.\n",
        "##### Ensure that your code is clear and readable.\n",
        "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDkEQXlQdROm"
      },
      "source": [
        "## Data Cleaning\n",
        "We cleaned the dataset to remove data with missing values, and store it as a new dataset.\n",
        "\n",
        "First, we obtained relevant information about the data to decide how we should deal with certain variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r-QHm8N-BYL"
      },
      "outputs": [],
      "source": [
        "# Information about the data\n",
        "data.info()\n",
        "data.describe()\n",
        "data.isna().sum() # this checks how many NA values are there in each column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySNxypQIw8Tn"
      },
      "source": [
        "Then, we start doing the data cleaning. We removed columns where the variable is not relevant to our analysis, and filled NA values with 0 where appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr41TEb5WYXx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "f185bc21-390d-4104-e5bc-6981fa8e1027"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d62a2b6a0af3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Drop the unnecessary columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m data_cleaned = data.drop(columns = [\"SIC Code\", \"Industry\", \"8-Digit SIC Description\", \"Company Description\", \"Year Found\",\n\u001b[0m\u001b[1;32m      3\u001b[0m                                     \u001b[0;34m\"Square Footage\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fiscal Year End\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LATITUDE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LONGITUDE\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \"Employees (Single Site)\", \"Parent Company\", \"Company Status (Active/Inactive)\"])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "# Drop the unnecessary columns\n",
        "data_cleaned = data.drop(columns = [\"SIC Code\", \"Industry\", \"8-Digit SIC Description\", \"Company Description\", \"Year Found\",\n",
        "                                    \"Square Footage\", \"Fiscal Year End\", \"LATITUDE\", \"LONGITUDE\",\n",
        "                                    \"Employees (Single Site)\", \"Parent Company\", \"Company Status (Active/Inactive)\"])\n",
        "\n",
        "# Cast selected variables to integer\n",
        "columns_to_fill = [\"Employees (Global Ultimate Total)\", \"Is Domestic Ultimate\", \"Is Global Ultimate\"]\n",
        "\n",
        "data_cleaned[columns_to_fill] = data_cleaned[columns_to_fill].fillna(0)\n",
        "\n",
        "data_cleaned.astype({\"Employees (Global Ultimate Total)\": \"int\",\n",
        "                     \"Is Domestic Ultimate\": \"int\",\n",
        "                     \"Is Global Ultimate\": \"int\"})\n",
        "\n",
        "# Replace 'Public Sector' with 'Public' in 'Ownership Type'\n",
        "data_cleaned['Ownership Type'].replace('Public Sector', 'Public', inplace=True)\n",
        "\n",
        "# Manipulate Import/Export Status\n",
        "data_cleaned['Exports'] = 0\n",
        "data_cleaned['Imports'] = 0\n",
        "data_cleaned.loc[data_cleaned['Import/Export Status'] == 'Exports', 'Exports'] = 1\n",
        "data_cleaned.loc[data_cleaned['Import/Export Status'] == 'Imports', 'Imports'] = 1\n",
        "data_cleaned.loc[data_cleaned['Import/Export Status'] == 'Both Imports & Exports', ['Exports', 'Imports']] = 1\n",
        "data_cleaned.drop(columns = ['Import/Export Status'], inplace = True)\n",
        "\n",
        "# fill up the Domestic Ultimate Company column if it is empty\n",
        "data_cleaned.loc[data_cleaned[\"Global Ultimate Country\"] == \"Singapore\", \"Domestic Ultimate Company\"] = data_cleaned[\"Global Ultimate Company\"]\n",
        "\n",
        "# clean the employees columns\n",
        "data_cleaned.loc[data_cleaned[\"Parent Country\"] == \"Singapore\", \"Employees (Domestic Ultimate Total)\"] = data_cleaned[\"Employees (Global Ultimate Total)\"]\n",
        "\n",
        "# Fill missing values in 'Employees (Domestic Ultimate Total)' with 0\n",
        "data_cleaned['Employees (Domestic Ultimate Total)'].fillna(0, inplace=True)\n",
        "\n",
        "# global ultimate total should not be less than the domestic ultimate total\n",
        "data_cleaned.loc[data_cleaned[\"Employees (Global Ultimate Total)\"] < data_cleaned[\"Employees (Domestic Ultimate Total)\"], \"Employees (Global Ultimate Total)\"] = data_cleaned[\"Employees (Domestic Ultimate Total)\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbbz342BdTlQ"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3takArfxzW2"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We extracted out the relevant categories and used k-fold cross-validation to split the data into training and testing data respectively."
      ],
      "metadata": {
        "id": "CpNVmqJiuxjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the target variable you want to predict\n",
        "target_variable = 'Sales (Global Ultimate Total USD)'\n",
        "\n",
        "# Drop non-numeric columns or encode categorical variables as needed\n",
        "non_numeric_columns = ['AccountID', 'Company', 'Entity Type', 'Parent Country',\n",
        "                       'Ownership Type', 'Global Ultimate Company',\n",
        "                       'Global Ultimate Country', 'Domestic Ultimate Company']\n",
        "data_numeric = data_cleaned.drop(non_numeric_columns, axis=1)\n",
        "\n",
        "# Extract features (X) and target variable (y)\n",
        "X = data_numeric.drop([target_variable, '8-Digit SIC Code'], axis=1) # Drop the target variable from features\n",
        "y = data_numeric[target_variable]"
      ],
      "metadata": {
        "id": "jcrkDR2-rr8m",
        "outputId": "52672d83-eb44-42da-b537-fc7a4b36952b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data_cleaned' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f7cc035ec5d3>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                        \u001b[0;34m'Ownership Type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Global Ultimate Company'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                        'Global Ultimate Country', 'Domestic Ultimate Company']\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_numeric_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Extract features (X) and target variable (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_cleaned' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djH0VVyUcqzl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "4d224127-b73a-442f-d1d3-14b34d215550"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-52bddf9fb60d>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0;31m# this gets the indices of the training and testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ],
      "source": [
        "xgb_regressor = XGBRegressor(n_estimators = 5000, learning_rate = 1.0, max_depth = 1, objective = \"reg:squarederror\")\n",
        "\n",
        "# Store the MSE scores and R^2 Scores for the k-fold CV\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Split the data into k folds\n",
        "k = 50\n",
        "kf = KFold(n_splits = k, shuffle = True, random_state = 42)\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "  # this gets the indices of the training and testing data\n",
        "  X_train = X.iloc[train_index]\n",
        "  X_test = X.iloc[test_index]\n",
        "  y_train= y.iloc[train_index]\n",
        "  y_test = y.iloc[test_index]\n",
        "\n",
        "  # fit the data with the model\n",
        "  xgb_regressor.fit(X_train, y_train)\n",
        "  y_pred = xgb_regressor.predict(X_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  r_squared = r2_score(y_test, y_pred)\n",
        "  mse_scores.append(mse)\n",
        "  r2_scores.append(r_squared)\n",
        "\n",
        "# Get the average MSE and R^2 scores\n",
        "print(\"MSE score: \", np.mean(mse_scores))\n",
        "print(\"R^2 score: \", np.mean(r2_scores))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4r10u8_Rwqj"
      },
      "source": [
        "## The cell below is **NOT** to be removed\n",
        "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list).\n",
        "##### It is recommended to test the function out prior to submission\n",
        "-------------------------------------------------------------------------------------------------------------------------------\n",
        "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
        "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBTcn-TFRwqj"
      },
      "outputs": [],
      "source": [
        "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
        "    '''DO NOT REMOVE THIS FUNCTION.\n",
        "\n",
        "The function accepts a dataframe as input and return an iterable (list)\n",
        "of binary classes as output.\n",
        "\n",
        "The function should be coded to test on hidden data\n",
        "and should include any preprocessing functions needed for your model to perform.\n",
        "\n",
        "All relevant code MUST be included in this function.'''\n",
        "\n",
        "    result = []\n",
        "\n",
        "\n",
        "    # Part 1: Data Cleaning\n",
        "    data_cleaned = hidden_data.drop(columns = [\"SIC Code\", \"Industry\", \"8-Digit SIC Description\", \"Company Description\", \"Year Found\",\n",
        "                                        \"Square Footage\", \"Fiscal Year End\", \"LATITUDE\", \"LONGITUDE\",\n",
        "                                        \"Employees (Single Site)\", \"Parent Company\", \"Company Status (Active/Inactive)\"])\n",
        "\n",
        "    # Cast selected variables to integer\n",
        "    columns_to_fill = [\"Employees (Global Ultimate Total)\", \"Is Domestic Ultimate\", \"Is Global Ultimate\"]\n",
        "\n",
        "    data_cleaned[columns_to_fill] = data_cleaned[columns_to_fill].fillna(0)\n",
        "\n",
        "    data_cleaned.astype({\"Employees (Global Ultimate Total)\": \"int\",\n",
        "                        \"Is Domestic Ultimate\": \"int\",\n",
        "                        \"Is Global Ultimate\": \"int\"})\n",
        "\n",
        "    # Replace 'Public Sector' with 'Public' in 'Ownership Type'\n",
        "    data_cleaned['Ownership Type'].replace('Public Sector', 'Public', inplace=True)\n",
        "\n",
        "    # Manipulate Import/Export Status\n",
        "    data_cleaned['Exports'] = 0\n",
        "    data_cleaned['Imports'] = 0\n",
        "    data_cleaned.loc[data_cleaned['Import/Export Status'] == 'Exports', 'Exports'] = 1\n",
        "    data_cleaned.loc[data_cleaned['Import/Export Status'] == 'Imports', 'Imports'] = 1\n",
        "    data_cleaned.loc[data_cleaned['Import/Export Status'] == 'Both Imports & Exports', ['Exports', 'Imports']] = 1\n",
        "    data_cleaned.drop(columns = ['Import/Export Status'], inplace = True)\n",
        "\n",
        "    # fill up the Domestic Ultimate Company column if it is empty\n",
        "    data_cleaned.loc[data_cleaned[\"Global Ultimate Country\"] == \"Singapore\", \"Domestic Ultimate Company\"] = data_cleaned[\"Global Ultimate Company\"]\n",
        "\n",
        "    # clean the employees columns\n",
        "    data_cleaned.loc[data_cleaned[\"Parent Country\"] == \"Singapore\", \"Employees (Domestic Ultimate Total)\"] = data_cleaned[\"Employees (Global Ultimate Total)\"]\n",
        "\n",
        "    # Fill missing values in 'Employees (Domestic Ultimate Total)' with 0\n",
        "    data_cleaned['Employees (Domestic Ultimate Total)'].fillna(0, inplace=True)\n",
        "\n",
        "    # global ultimate total should not be less than the domestic ultimate total\n",
        "    data_cleaned.loc[data_cleaned[\"Employees (Global Ultimate Total)\"] < data_cleaned[\"Employees (Domestic Ultimate Total)\"], \"Employees (Global Ultimate Total)\"] = data_cleaned[\"Employees (Domestic Ultimate Total)\"]\n",
        "\n",
        "\n",
        "    # Part 2: Extract features and target variable\n",
        "    # Choose the target variable you want to predict\n",
        "    target_variable = 'Sales (Global Ultimate Total USD)'\n",
        "\n",
        "    # Drop non-numeric columns or encode categorical variables as needed\n",
        "    non_numeric_columns = ['AccountID', 'Company', 'Entity Type', 'Parent Country',\n",
        "                          'Ownership Type', 'Global Ultimate Company',\n",
        "                          'Global Ultimate Country', 'Domestic Ultimate Company']\n",
        "    data_numeric = data_cleaned.drop(non_numeric_columns, axis=1)\n",
        "\n",
        "    # Extract features (X) and target variable (y)\n",
        "    X = data_numeric.drop([target_variable, '8-Digit SIC Code'], axis=1) # Drop the target variable from features\n",
        "    y = data_numeric[target_variable]\n",
        "\n",
        "\n",
        "    # Part 3: XGBoost Model\n",
        "    xgb_regressor = XGBRegressor(n_estimators = 5000, learning_rate = 1.0, max_depth = 1, objective = \"reg:squarederror\")\n",
        "\n",
        "    # Store the MSE scores and R^2 Scores for the k-fold CV\n",
        "    mse_scores = []\n",
        "    r2_scores = []\n",
        "\n",
        "    # Split the data into k folds\n",
        "    k = 50\n",
        "    kf = KFold(n_splits = k, shuffle = True, random_state = 42)\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "      # this gets the indices of the training and testing data\n",
        "      X_train = X.iloc[train_index]\n",
        "      X_test = X.iloc[test_index]\n",
        "      y_train= y.iloc[train_index]\n",
        "      y_test = y.iloc[test_index]\n",
        "\n",
        "      # fit the data with the model\n",
        "      xgb_regressor.fit(X_train, y_train)\n",
        "      y_pred = xgb_regressor.predict(X_test)\n",
        "      mse = mean_squared_error(y_test, y_pred)\n",
        "      r_squared = r2_score(y_test, y_pred)\n",
        "      mse_scores.append(mse)\n",
        "      r2_scores.append(r_squared)\n",
        "\n",
        "    # result\n",
        "    result.append(np.mean(mse_scores))\n",
        "    result.append(np.mean(r2_scores))\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjnF4Us3Rwqj"
      },
      "source": [
        "##### Cell to check testing_hidden_data function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoKuMWr3Rwqj"
      },
      "outputs": [],
      "source": [
        "# This cell should output a list of predictions.\n",
        "test_df = pd.read_csv(filepath)\n",
        "test_df = test_df.drop(columns=['Sales (Domestic Ultimate Total USD)'])\n",
        "print(testing_hidden_data(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHmFJpR8Rwqj"
      },
      "source": [
        "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}